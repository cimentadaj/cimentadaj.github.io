<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Pisa on Jorge Cimentada</title>
    <link>/tags/pisa/</link>
    <description>Recent content in Pisa on Jorge Cimentada</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <lastBuildDate>Wed, 08 Mar 2017 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/tags/pisa/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>My PISA twitter bot</title>
      <link>/blog/2017-03-08-my-pisa-twitter-bot/my-pisa-twitter-bot/</link>
      <pubDate>Wed, 08 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>/blog/2017-03-08-my-pisa-twitter-bot/my-pisa-twitter-bot/</guid>
      <description>&lt;p&gt;I’ve long wanted to prepare a project with R related to education. I knew I’d found the idea when I read Thomas Lumley’s &lt;a href=&#34;http://notstatschat.tumblr.com/post/156007757906/a-bus-watching-bot&#34;&gt;attempt to create a Twitter bot in which he tweeted bus arrivals in New Zealand&lt;/a&gt;. Quoting him, “Is it really hard to write a bot? No. Even I can do it. And I’m old.”&lt;/p&gt;
&lt;p&gt;So I said to myself, alright, you have to create a Twitter bot but it has to be related to education. It’s an easy project which shouldn’t take a lot of your time. I then came up with this idea: what if you could randomly sample questions from the &lt;a href=&#34;http://www.oecd.org/pisa/aboutpisa/&#34;&gt;PISA databases&lt;/a&gt; and create a sort of random facts generator. The result would be one graph a day, showing a question for some random sample of countries. I figured, why not prepare a post (both for me to remember how I did it but also so others can contribute to the project) where I explained step-by-step how I did it?&lt;/p&gt;
&lt;p&gt;The repository for the project is &lt;a href=&#34;https://github.com/cimentadaj/PISAfacts_twitterBot&#34;&gt;here&lt;/a&gt;, so feel free to drop any comments or improvements. The idea is to load the &lt;a href=&#34;http://vs-web-fs-1.oecd.org/pisa/PUF_SPSS_COMBINED_CMB_STU_QQQ.zip&#34;&gt;PISA 2015 data&lt;/a&gt;, randomly pick a question that doesn’t have a lot of labels (because then it’s very difficult to plot it nicely), and based on the type of question create an appropriate graph. Of course, all of this needs to be done on the fly, without human assistance. You can follow this twitter account at &lt;span class=&#34;citation&#34;&gt;@DailyPISA_Facts&lt;/span&gt;. Let’s start!&lt;/p&gt;
&lt;div id=&#34;data-wrangling&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data wrangling&lt;/h2&gt;
&lt;p&gt;First we load some of the packages we’ll use and read the PISA 2015 student data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(forcats)
library(haven)
library(intsvy) # For correct estimation of PISA estimates
library(countrycode) # For countrycodes
library(cimentadaj) # devtools::install_github(&amp;quot;cimentadaj/cimentadaj&amp;quot;)
library(lazyeval)
library(ggthemes) # devtools::install_github(&amp;quot;jrnold/ggthemes&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;file_name &amp;lt;- file.path(tempdir(), &amp;quot;pisa.zip&amp;quot;)

download.file(
  &amp;quot;http://vs-web-fs-1.oecd.org/pisa/PUF_SPSS_COMBINED_CMB_STU_QQQ.zip&amp;quot;,
  destfile = file_name
)

unzip(file_name, exdir = tempdir())

pisa_2015 &amp;lt;- read_spss(file.path(tempdir(), &amp;quot;CY6_MS_CMB_STU_QQQ.sav&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In my system it takes about 2 minutes. Make sure to download the zip file from the link above to download the datasets. (We could’ve downloaded the data from R to a temporary file and then delete it but since we’ll be tweeting every single day I though that having the data in my system would be a smarter move)&lt;/p&gt;
&lt;p&gt;The idea is to generate a script that can be used with all PISA datasets, so at some point we should be able not only to randomly pick question but also randomly pick PISA surveys (PISA has been implemented since the year 2000 in three year intervals). We create some places holders for the variable country name, the format of the country names and the missing labels we want to ignore for each question (I think these labels should be the same across all surveys).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;country_var &amp;lt;- &amp;quot;cnt&amp;quot;
country_types &amp;lt;- &amp;quot;iso3c&amp;quot;

missing_labels &amp;lt;- c(&amp;quot;Valid Skip&amp;quot;,
                    &amp;quot;Not Reached&amp;quot;,
                    &amp;quot;Not Applicable&amp;quot;,
                    &amp;quot;Invalid&amp;quot;,
                    &amp;quot;No Response&amp;quot;)

int_data &amp;lt;- pisa_2015 # Create a safe copy of the data, since it takes about 2 mins to read.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After this, I started doing some basic data manipulation. Each line is followed by a comment on why I did it.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;names(int_data) &amp;lt;- tolower(names(int_data)) # It&amp;#39;s easier to write variable names as lower case
int_data$region &amp;lt;- countrycode(int_data[[country_var]], country_types, &amp;quot;continent&amp;quot;)
# Create a region variable to add regional colours to plots at some point.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Most PISA datasets are in SPSS format, where the variable’s question has been written as a label. If you’ve used SPSS or SAS you know that labels are very common; they basically outline the question of that variable. In R, this didn’t properly exists until the &lt;code&gt;foreign&lt;/code&gt; and &lt;code&gt;haven&lt;/code&gt; package. With &lt;code&gt;read_spss()&lt;/code&gt;, each variable has now two important attributes called &lt;code&gt;label&lt;/code&gt; and &lt;code&gt;labels&lt;/code&gt;. Respectively, the first one contains the question, while the second contains the value labels (assuming the file to be read has these labels). This information will be vital to our PISA bot. In fact, this script works only if the data has these two attributes. If you’re feeling particularly adventurous, you can fork this repository and make the script work also with metadata!&lt;/p&gt;
&lt;p&gt;Have a look at the country names in &lt;code&gt;int_data[[country_var]][1:10]&lt;/code&gt;. They’re all written as 3-letter country codes. But to our luck, the &lt;code&gt;labels&lt;/code&gt; attribute has the correct names with the 3-letter equivalent. We can save these attributes and recode the 3-letter country name to long names.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Saving country names to change 3 letter country name to long country names
country_labels &amp;lt;- attr(int_data[[country_var]], &amp;quot;labels&amp;quot;)

# Reversing the 3-letter code to names so I can search for countries
# in a lookup table
country_names &amp;lt;- reverse_name(country_labels)

# Lookup 3-letter code and change them for long country names
int_data[, country_var] &amp;lt;- country_names[int_data[[country_var]]]
attr(int_data[[country_var]], &amp;quot;labels&amp;quot;) &amp;lt;- country_labels&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next thing I’d like to do is check which variables will be valid, i.e. those which have a &lt;code&gt;labels&lt;/code&gt; attribute, have 2 or more &lt;code&gt;labels&lt;/code&gt; aside from the &lt;code&gt;missing&lt;/code&gt; category of labels and are not either characters or factors (remember that all variables should be numeric with an attribute that contains the labels; character columns are actually invalid here). This will give me the list of variables that I’ll be able to use.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;subset_vars &amp;lt;- 
  int_data %&amp;gt;%
  map_lgl(function(x)
    !is.null(attr(x, &amp;quot;labels&amp;quot;)) &amp;amp;&amp;amp;
    length(setdiff(names(attr(x, &amp;quot;labels&amp;quot;)), missing_labels)) &amp;gt;= 2 &amp;amp;&amp;amp;
    !typeof(x) %in% c(&amp;quot;character&amp;quot;, &amp;quot;factor&amp;quot;)) %&amp;gt;%
  which()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Great, we have our vector of valid columns.&lt;/p&gt;
&lt;p&gt;The next steps are fairly straight forward. I randomply sample one of those indexes (which have the variale name as a &lt;code&gt;names&lt;/code&gt; attribute, check &lt;code&gt;subset_vars&lt;/code&gt;), together with the &lt;code&gt;cnt&lt;/code&gt; and &lt;code&gt;region&lt;/code&gt; variables.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;valid_df_fun &amp;lt;- function(data, vars_select) {
  data %&amp;gt;%
  select_(&amp;quot;cnt&amp;quot;, &amp;quot;region&amp;quot;, sample(names(vars_select), 1)) %&amp;gt;%
  as.data.frame()
}

valid_df &amp;lt;- valid_df_fun(int_data, subset_vars)
random_countries &amp;lt;- unique(valid_df$cnt) # To sample unique countries later on&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We also need to check how many labels we have, aside from the &lt;code&gt;missing&lt;/code&gt; labels. In any case, if those unique labels have more than 5, we need to resample a new variable. It’s difficult to understand a plot with that many labels. We need to make our plots as simple and straightforward as possible.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;var_labels &amp;lt;- attr(valid_df[[names(valid_df)[3]]], &amp;#39;labels&amp;#39;) # Get labels

# Get unique labels
valid_labels &amp;lt;- function(variable_label, miss) {
  variable_label %&amp;gt;%
    names() %&amp;gt;%
    setdiff(miss)
}

len_labels &amp;lt;- length(valid_labels(var_labels, missing_labels)) # length of unique labels

# While the length of the of the labels is &amp;gt; 4, sample a new variable.
while (len_labels &amp;gt; 4) {
  valid_df &amp;lt;- valid_df_fun(int_data, subset_vars)
  var_labels &amp;lt;- attr(valid_df[[names(valid_df)[3]]], &amp;#39;labels&amp;#39;) # Get labels
  len_labels &amp;lt;- length(valid_labels(var_labels, missing_labels))
}

# Make 100% sure we get the results:
stopifnot(len_labels &amp;lt;= 4)

(labels &amp;lt;- reverse_name(var_labels)) 
# Reverse vector names to objects and viceversa for 
# later recoding.

var_name &amp;lt;- names(valid_df)[3]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before estimating the &lt;code&gt;PISA&lt;/code&gt; proportions, I want to create a record of all variables that have been used. Whenever a graph has something wrong we wanna know which variable it was, so we can reproduce the problem and fix it later in the future.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;new_var &amp;lt;- paste(var_name, Sys.Date(), sep = &amp;quot; - &amp;quot;)
write_lines(new_var, path = &amp;quot;./all_variables.txt&amp;quot;, append = T) 
# I create an empty .txt file to write the vars&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now comes the estimation section. Using the &lt;code&gt;pisa.table&lt;/code&gt; function from the package &lt;code&gt;intsvy&lt;/code&gt; we can correctly estimate the population proportions of any variable for any valid country. This table will be the core data behind our plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;try_df &amp;lt;-
  valid_df %&amp;gt;%
  filter(!is.na(region)) %&amp;gt;%
  pisa.table(var_name, data = ., by = &amp;quot;cnt&amp;quot;) %&amp;gt;%
  filter(complete.cases(.))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s check out the contents of &lt;code&gt;try_df&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##          cnt ec015q08na Freq Percentage Std.err.
## 1  Australia          1 4750      84.15        0
## 2  Australia          2  895      15.85        0
## 3    Belgium          1 1204      88.53        0
## 4    Belgium          2  156      11.47        0
## 5   Bulgaria          1 2850      77.01        0
## 6   Bulgaria          2  851      22.99        0
## 7    Croatia          1 2232      82.30        0
## 8    Croatia          2  480      17.70        0
## 9    Denmark          1  897      81.99        0
## 10   Denmark          2  197      18.01        0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Great! To finish with the data, we simply need one more thing: to recode the value labels with the &lt;code&gt;labels&lt;/code&gt; vector.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;try_df[var_name] &amp;lt;- labels[try_df[, var_name]]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Awesome. We have the data ready, more or less. Let’s produce a dirty plot to check how long the title is.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;title_question &amp;lt;- attr(valid_df[, var_name], &amp;#39;label&amp;#39;)

ggplot(try_df, aes_string(names(try_df)[2], &amp;quot;Percentage&amp;quot;)) +
  geom_col() +
  xlab(title_question)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/2017-03-08-my-pisa-twitter-bot/2017-03-08-my-pisa-twitter-bot_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note: Because the question is randomly sampled, you might be getting a short title. Rerun the script and eventually you’ll get a long one.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;So, the question &lt;em&gt;might&lt;/em&gt; have two problems. The wording is a bit confusing (something we can’t really do anything about because that’s how it’s written in the questionnaire) and it’s too long. For the second problem I created a function that cuts the title in an arbitrary cutoff point (based on experimental tests on how many letters fit into a ggplot coordinate plane) but it makes sure that the cutoff is not in the middle of a word, i.e. it searches for the closest end of a word.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Section: Get the title
cut &amp;lt;- 60 # Arbitrary cutoff

# This function accepts a sentence (or better, a title) and cuts it between
# the start and cutoff arguments (just as substr).
# But if the cutoff is not an empty space it will search +-1 index by
# index from the cutoff point until it reaches
# the closest empty space. It will return from start to the new cutoff
sentence_cut &amp;lt;- function(sentence, start, cutoff) {
  
  if (nchar(sentence) &amp;lt;= cutoff) return(substr(sentence, start, cutoff))
  
  excerpt &amp;lt;- substr(sentence, start, cutoff)
  actual_val &amp;lt;- cutoff
  neg_val &amp;lt;- pos_val &amp;lt;- actual_val
  
  if (!substr(excerpt, actual_val, actual_val) == &amp;quot; &amp;quot;) {
    
    expr &amp;lt;- c(substr(sentence, neg_val, neg_val) == &amp;quot; &amp;quot;, substr(sentence, pos_val, pos_val) == &amp;quot; &amp;quot;)
    
    while (!any(expr)) {
      neg_val &amp;lt;- neg_val - 1
      pos_val &amp;lt;- pos_val + 1
      
      expr &amp;lt;- c(substr(sentence, neg_val, neg_val) == &amp;quot; &amp;quot;, substr(sentence, pos_val, pos_val) == &amp;quot; &amp;quot;)
    }
    
    cutoff &amp;lt;- ifelse(which(expr) == 1, neg_val, pos_val)
    excerpt &amp;lt;- substr(sentence, start, cutoff)
    return(excerpt)
    
  } else {
    
    return(excerpt)
    
  }
}

# How many lines in ggplot2 should this new title have? Based on the cut off
sentence_vecs &amp;lt;- ceiling(nchar(title_question) / cut)

# Create an empty list with the length of `lines` of the title.
# In this list I&amp;#39;ll paste the divided question and later paste them together
list_excerpts &amp;lt;- replicate(sentence_vecs, vector(&amp;quot;character&amp;quot;, 0))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Just to make sure our function works, let’s do some quick tests. Let’s create the sentence &lt;code&gt;This is my new sentence&lt;/code&gt; and subset from index &lt;code&gt;1&lt;/code&gt; to index &lt;code&gt;17&lt;/code&gt;. Index &lt;code&gt;17&lt;/code&gt; is the letter &lt;code&gt;e&lt;/code&gt; from the word &lt;code&gt;sentence&lt;/code&gt;, so we should cut the sentence to the closest space, in our case, &lt;code&gt;This is my new&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sentence_cut(&amp;quot;This is my new sentence&amp;quot;, 1, 17)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;This is my new &amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A more complicated test using &lt;code&gt;I want my sentence to be cut where no word is still running&lt;/code&gt;. Let’s pick from index &lt;code&gt;19&lt;/code&gt;, which is the space between &lt;code&gt;sentence&lt;/code&gt; and &lt;code&gt;to&lt;/code&gt;, the index &lt;code&gt;27&lt;/code&gt;, which is the &lt;code&gt;u&lt;/code&gt; of &lt;code&gt;cut&lt;/code&gt;. Because the length to a space &lt;code&gt;-1 and +1&lt;/code&gt; is the same both ways, the function always picks the shortest length as a defensive mechanism to long titles.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sentence_cut(&amp;quot;I want my sentence to be cut where no word is still running&amp;quot;, 19, 27)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot; to be &amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that we have the function ready, we have to automate the process so that the first line is cut, then the second line should start where the first line left off and so on.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;for (list_index in seq_along(list_excerpts)) {
  
  non_empty_list &amp;lt;- Filter(f = function(x) !(is_empty(x)), list_excerpts)
  
  # If this is the first line, the start should 1, otherwise the sum of all characters
  # of previous lines
  start &amp;lt;- ifelse(list_index == 1, 1, sum(map_dbl(non_empty_list, nchar)))
  
  # Because start gets updated every iteration, simply cut from start to start + cut
  # The appropriate exceptions are added when its the first line of the plot.
  list_excerpts[[list_index]] &amp;lt;-
    sentence_cut(title_question, start, ifelse(list_index == 1, cut, start + cut))
}

final_title &amp;lt;- paste(list_excerpts, collapse = &amp;quot;\n&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above loop gives you a list with the title separate into N lines based on the cutoff point. For the ggplot title, we finish by collapsing the separate titles with the &lt;code&gt;\n&lt;/code&gt; as the separator.&lt;/p&gt;
&lt;p&gt;So, I wrapped all of this into this function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;label_cutter &amp;lt;- function(variable_labels, cut) {
  
  variable_label &amp;lt;- unname(variable_labels)
  
  # This function accepts a sentence (or better, a title) and cuts it between
  # the start and cutoff arguments ( just as substr). But if the cutoff is not an empty space
  # it will search +-1 index by index from the cutoff point until it reaches
  # the closest empty space. It will return from start to the new cutoff
  sentence_cut &amp;lt;- function(sentence, start, cutoff) {
    
    if (nchar(sentence) &amp;lt;= cutoff) return(substr(sentence, start, cutoff))
    
    excerpt &amp;lt;- substr(sentence, start, cutoff)
    actual_val &amp;lt;- cutoff
    neg_val &amp;lt;- pos_val &amp;lt;- actual_val
    
    if (!substr(excerpt, actual_val, actual_val) == &amp;quot; &amp;quot;) {
      
      expr &amp;lt;- c(substr(sentence, neg_val, neg_val) == &amp;quot; &amp;quot;, substr(sentence, pos_val, pos_val) == &amp;quot; &amp;quot;)
      
      while (!any(expr)) {
        neg_val &amp;lt;- neg_val - 1
        pos_val &amp;lt;- pos_val + 1
        
        expr &amp;lt;- c(substr(sentence, neg_val, neg_val) == &amp;quot; &amp;quot;, substr(sentence, pos_val, pos_val) == &amp;quot; &amp;quot;)
      }
      
      cutoff &amp;lt;- ifelse(which(expr) == 1, neg_val, pos_val)
      excerpt &amp;lt;- substr(sentence, start, cutoff)
      return(excerpt)
      
    } else {
      
      return(excerpt)
      
    }
  }
  
  # How many lines should this new title have? Based on the cut off
  sentence_vecs &amp;lt;- ceiling(nchar(variable_label) / cut)
  
  # Create an empty list with the amount of lines for the excerpts
  # to be stored.
  list_excerpts &amp;lt;- replicate(sentence_vecs, vector(&amp;quot;character&amp;quot;, 0))
  
  for (list_index in seq_along(list_excerpts)) {
    
    non_empty_list &amp;lt;- Filter(f = function(x) !(is_empty(x)), list_excerpts)
    
    # If this is the first line, the start should 1, otherwise the sum of all characters
    # of previous lines
    start &amp;lt;- ifelse(list_index == 1, 1, sum(map_dbl(non_empty_list, nchar)))
    
    # Because start gets updated every iteration, simply cut from start to start + cut
    # The appropriate exceptions are added when its the first line of the plot.
    list_excerpts[[list_index]] &amp;lt;-
      sentence_cut(variable_label, start, ifelse(list_index == 1, cut, start + cut))
  }
  
  final_title &amp;lt;- paste(list_excerpts, collapse = &amp;quot;\n&amp;quot;)
  final_title
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The function accepts a string and a cut off point. It will automatically create new lines if needed and return the separated title based on the cutoff point. We apply this function over the title and the labels, to make sure everything is clean.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;final_title &amp;lt;- label_cutter(title_question, 60)
labels &amp;lt;- map_chr(labels, label_cutter, 35)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, as I’ve outlined above, each question should have less then four labels. I though that it might be a good idea if I created different graphs for different number of labels. For example, for the two label questions, I thought a simple dot plot might be a good idea —— the space between the dots will sum up to one making it quite intuitive. However, for three and four labels, I though of a cutomized dotplot.&lt;/p&gt;
&lt;p&gt;At the time I was writing this bot I was learning object oriented programming, so I said to myself, why not create a generic function that generates different plots for different labels? First, I need to assign the data frame the appropriate class.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;label_class &amp;lt;-
  c(&amp;quot;2&amp;quot; = &amp;quot;labeltwo&amp;quot;, &amp;#39;3&amp;#39; = &amp;quot;labelthree&amp;quot;, &amp;#39;4&amp;#39; = &amp;quot;labelfour&amp;quot;)[as.character(len_labels)]

class(try_df) &amp;lt;- c(class(try_df), label_class)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The generic function, together with its cousin functions, are located in the &lt;code&gt;ggplot_funs.R&lt;/code&gt; script in the PISA bot repository linked in the beginning.&lt;/p&gt;
&lt;p&gt;The idea is simple. Create a generic function that dispatches based on the class of the object.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pisa_graph &amp;lt;- function(data, y_title, fill_var) UseMethod(&amp;quot;pisa_graph&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pisa_graph.labeltwo &amp;lt;- function(data, y_title, fill_var) {
  
  dots &amp;lt;- setNames(list(interp(~ fct_reorder2(x, y, z),
                               x = quote(cnt),
                               y = as.name(fill_var),
                               z = quote(Percentage))), &amp;quot;cnt&amp;quot;)
  # To make sure we can randomly sample a number lower than the length
  unique_cnt &amp;lt;- length(unique(data$cnt))
  
  data %&amp;gt;%
    filter(cnt %in% sample(unique(cnt), ifelse(unique_cnt &amp;gt;= 15, 15, 10))) %&amp;gt;%
    mutate_(.dots = dots) %&amp;gt;%
    ggplot(aes(cnt, Percentage)) +
    geom_point(aes_string(colour = fill_var)) +
    labs(y = y_title, x = NULL) +
    scale_colour_discrete(name = NULL) +
    guides(colour = guide_legend(nrow = 1)) +
    scale_y_continuous(limits = c(0, 100),
                       breaks = seq(0, 100, 20),
                       labels = paste0(seq(0, 100, 20), &amp;quot;%&amp;quot;)) +
    coord_flip() +
    theme_minimal() +
    theme(legend.position = &amp;quot;top&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is the graph for the &lt;code&gt;labeltwo&lt;/code&gt; class. Using a work around for non-standard evaluation, I reorder the &lt;code&gt;x&lt;/code&gt; axis. This took me some time to understand but it’s very easy once you’ve written two or three expressions. Create a list with the formula (this might be for &lt;code&gt;mutate&lt;/code&gt;, &lt;code&gt;filter&lt;/code&gt; or whatever &lt;code&gt;tidyverse&lt;/code&gt; function) and &lt;strong&gt;rename&lt;/strong&gt; the placeholders in the formula with the appropriate names. Make sure to name that list object with the new variable name you want for this variable. So, for my example, we’re creating a new variable called &lt;code&gt;cnt&lt;/code&gt; that will be the same variable reordered by the &lt;code&gt;fill_var&lt;/code&gt; and the &lt;code&gt;Percentage&lt;/code&gt; variable.&lt;/p&gt;
&lt;p&gt;After this, I just built a usual &lt;code&gt;ggplot2&lt;/code&gt; object (although notice that I used &lt;code&gt;mutate_&lt;/code&gt; instead of &lt;code&gt;mutate&lt;/code&gt; for the non-standard evaluation).&lt;/p&gt;
&lt;p&gt;If you’re interested in learning more about standard and non-standard evaluation, I found these resources very useful (&lt;a href=&#34;http://www.carlboettiger.info/2015/02/06/fun-standardizing-non-standard-evaluation.html&#34;&gt;here&lt;/a&gt;, &lt;a href=&#34;http://adv-r.had.co.nz/Computing-on-the-language.html&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://cran.r-project.org/web/packages/lazyeval/vignettes/lazyeval.html&#34;&gt;here&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;The generic for &lt;code&gt;labelthree&lt;/code&gt; and &lt;code&gt;labelfour&lt;/code&gt; are pretty much the same as the previous plot but using a slightly different &lt;code&gt;geom&lt;/code&gt;. Have a look at the original file &lt;a href=&#34;https://raw.githubusercontent.com/cimentadaj/PISAfacts_twitterBot/master/ggplot_funs.R&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;We’ll, we’re almost there. After this, we simply, &lt;code&gt;source&lt;/code&gt; the &lt;code&gt;ggplot_funs.R&lt;/code&gt; script and produce the plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;source(&amp;quot;https://raw.githubusercontent.com/cimentadaj/PISAfacts_twitterBot/master/ggplot_funs.R&amp;quot;)
pisa_graph(data = try_df,
             y_title = final_title,
             fill_var = var_name)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/2017-03-08-my-pisa-twitter-bot/2017-03-08-my-pisa-twitter-bot_files/figure-html/unnamed-chunk-24-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;file &amp;lt;- tempfile()
ggsave(file, device = &amp;quot;png&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;setting-the-twitter-bot&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Setting the twitter bot&lt;/h2&gt;
&lt;p&gt;The final part is automating the twitter bot. I followed &lt;a href=&#34;https://www.r-bloggers.com/programming-a-twitter-bot-and-the-rescue-from-procrastination/&#34;&gt;this&lt;/a&gt; and &lt;a href=&#34;http://www.r-datacollection.com/blog/How-to-conduct-a-tombola-with-R/&#34;&gt;this&lt;/a&gt;. I won’t go into the specifics because I probably wouldn’t do justice to the the second post, but you have to create your account on Twitter, this will give you some keys that make sure you’re the right person. &lt;em&gt;You need to write these key-value pairs as environment variables&lt;/em&gt; (follow the second post) and then delete them from your R script (they’re secret! You shouldn’t keep them on your script but on some folder on your computer). Finally, make sure you identify your twitter account and make your first tweet!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(twitteR) # devtools::install_github(&amp;quot;geoffjentry/twitteR&amp;quot;)
setwd(&amp;quot;./folder_with_my_credentials/&amp;quot;)

api_key             &amp;lt;- Sys.getenv(&amp;quot;twitter_api_key&amp;quot;)
api_secret          &amp;lt;- Sys.getenv(&amp;quot;twitter_api_secret&amp;quot;)
access_token        &amp;lt;- Sys.getenv(&amp;quot;twitter_access_token&amp;quot;)
access_token_secret &amp;lt;- Sys.getenv(&amp;quot;twitter_access_token_secret&amp;quot;)
setup_twitter_oauth(api_key, api_secret, access_token, access_token_secret)

tweet(&amp;quot;&amp;quot;, mediaPath = file)
unlink(file)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That’s it! The last line should create the&lt;code&gt;tweet&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;automating-the-bot&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Automating the bot&lt;/h2&gt;
&lt;p&gt;The only thing left to do is automate this to run every day. I’ll explain how I did it for OSx by following &lt;a href=&#34;http://www.techradar.com/how-to/computing/apple/terminal-101-creating-cron-jobs-1305651&#34;&gt;this&lt;/a&gt; tutorial. You can find a Windows explanation in step 3 &lt;a href=&#34;https://www.r-bloggers.com/programming-a-twitter-bot-and-the-rescue-from-procrastination/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;First, we need to figure out the specific time we want to schedule the script. We define the time by filling out five stars:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;*****&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The first asterisk is for specifying the minute of the run (0-59)&lt;/li&gt;
&lt;li&gt;The second asterisk is for specifying the hour of the run (0-23)&lt;/li&gt;
&lt;li&gt;The third asterisk is for specifying the day of the month for the run (1-31)&lt;/li&gt;
&lt;li&gt;The fourth asterisk is for specifying the month of the run (1-12)&lt;/li&gt;
&lt;li&gt;The fifth asterisk is for specifying the day of the week (where Sunday is equal to 0, up to Saturday is equal to 6)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Taken from &lt;a href=&#34;http://www.techradar.com/how-to/computing/apple/terminal-101-creating-cron-jobs-1305651&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For example, let’s say we wanted to schedule the script for &lt;code&gt;3:00 pm&lt;/code&gt; every day, then the combination would be &lt;code&gt;0 15 * * *&lt;/code&gt;. If we wanted something every &lt;code&gt;15&lt;/code&gt; minutes, then &lt;code&gt;15 * * * *&lt;/code&gt; would do it. If we wanted to schedule the script for Mondays and Wednesdays at &lt;code&gt;15:00&lt;/code&gt; and &lt;code&gt;17:00&lt;/code&gt; respectively, then we would write &lt;code&gt;0 15,17 * * 1,3&lt;/code&gt;. In this last example the &lt;code&gt;* *&lt;/code&gt; are the placeholders for day of the month and month.&lt;/p&gt;
&lt;p&gt;In my example, I want the script to run every weekday at &lt;code&gt;9:30&lt;/code&gt; am, so my equivalent would be &lt;code&gt;30 9 * * 1-5&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To begin, we type &lt;code&gt;env EDITOR=nano crontab -e&lt;/code&gt; in the &lt;code&gt;terminal&lt;/code&gt; to initiate the &lt;code&gt;cron&lt;/code&gt; file that will run the script. Next, type our time schedule followed by the command that will run the script in R. The command is &lt;code&gt;RScript&lt;/code&gt;. However, because your terminal might not know where &lt;code&gt;RScript&lt;/code&gt; is we need to type the directory to where RScript is. Type &lt;code&gt;which RScript&lt;/code&gt; in the terminal and you shall get something like &lt;code&gt;/usr/local/bin/RScript&lt;/code&gt;. Then the expression would be something like &lt;code&gt;30 9 * * 1-5 /usr/local/bin/RScript path_to_your/script.R&lt;/code&gt;. See &lt;a href=&#34;https://support.rstudio.com/hc/en-us/articles/218012917-How-to-run-R-scripts-from-the-command-line&#34;&gt;here&lt;/a&gt; for the &lt;code&gt;RScript&lt;/code&gt; explanation.&lt;/p&gt;
&lt;p&gt;The whole sequence would be like this:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;env EDITOR=nano crontab -e
30 9 * * 1-5 /usr/local/bin/RScript path_to_your/script.R&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To save the file, press Control + O (to write out the file), then enter to accept the file name, then press Control + X (to exit nano). If all went well, then you should see “crontab: installing new crontab” without anything after that.&lt;/p&gt;
&lt;p&gt;Aaaaaand that’s it! You now have a working script that will be run from Monday to Friday at 9:30 am. This script will read the PISA data, pick a random variable, make a graph and tweet it. You can follow this twitter account at &lt;span class=&#34;citation&#34;&gt;[@DailyPISA_Facts]&lt;/span&gt;(&lt;a href=&#34;https://twitter.com/DailyPISA_Facts&#34; class=&#34;uri&#34;&gt;https://twitter.com/DailyPISA_Facts&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Hope this was useful!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Cognitive inequality around the world – Shiny app</title>
      <link>/blog/2016-12-12-cognitive-inequality-around-the-world--shiny-app/cognitive-inequality-around-the-world--shiny-app/</link>
      <pubDate>Mon, 12 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/2016-12-12-cognitive-inequality-around-the-world--shiny-app/cognitive-inequality-around-the-world--shiny-app/</guid>
      <description>&lt;p&gt;For the last month I’ve been working on this massive dataset that combines all PISA, TIMSS and PIRLS surveys into one major database. It has over 3 million students and over 2,000 variables, including student background and school and teacher information. I started playing around with it and ending up doing this: &lt;a href=&#34;https://cimentadaj.shinyapps.io/shiny/&#34; class=&#34;uri&#34;&gt;https://cimentadaj.shinyapps.io/shiny/&lt;/a&gt;. Feel free to check it out and drop any comments below.&lt;/p&gt;
&lt;p&gt;If you want to contribute, &lt;a href=&#34;https://github.com/cimentadaj/Inequality_Shinyapp&#34;&gt;this&lt;/a&gt; is the Github repository. I plan to keep adding some stuff to the app, including new surveys and automatic plot downloading, so don’t forget to check it out.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
