<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Scraping on Jorge Cimentada</title>
    <link>/tags/scraping/</link>
    <description>Recent content in Scraping on Jorge Cimentada</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <lastBuildDate>Fri, 01 Dec 2017 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/tags/scraping/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>How long should I wait for my bike?</title>
      <link>/blog/2017-12-01-how-long-should-i-wait-for-my-bike/how-long-should-i-wait-for-my-bike/</link>
      <pubDate>Fri, 01 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/blog/2017-12-01-how-long-should-i-wait-for-my-bike/how-long-should-i-wait-for-my-bike/</guid>
      <description>&lt;p&gt;I’ve just started a project which I’m very excited about. Everyday I take my bike to work and most days I have one of two problems. First, whenever I get to my station there are no bikes available; no problem, there’s an app that shows the closest stations with bikes available. The problem is that these stations might be far and sometimes I’m relucant to walk that much. I’d love for bicing to give me some time estimation until a new bike arrives.&lt;/p&gt;
&lt;p&gt;Second, whenever you’re trying to return a bike the station might not have any parking spaces available. Similarly, it would be very cool if bicing (the public bicycle company) gave me an estimate of how much time I should wait until a new bike will be taken. I started thinking on how I could implement this and started looking for bicing data online. To my surprise, bicing actually releases their &lt;strong&gt;live&lt;/strong&gt; data as a json! But for this type of estimation I need historical data. I want to know the pattern usage of the station and use that information for the prediction.&lt;/p&gt;
&lt;p&gt;With that idea in mind, I got to work. I needed to set up my Virtual Private Server (VPS) to pull the data from the bicing API everyday. Because this is still a work in progress, I will only describe here how I set my VPS to scrape the bicing API everyday and how I set &lt;code&gt;cron&lt;/code&gt; to send me an email after every scrape.&lt;/p&gt;
&lt;p&gt;I have a VPS from &lt;a href=&#34;https://www.digitalocean.com/&#34;&gt;Digital Ocean&lt;/a&gt; with an Ubuntu OS and 512 mb of RAM and 2 GB of hard disk. That’s enough for this task because the data should not be very big, even in the long run. In any case you can adjust for your VPS to have more memory/ram without losing information. Assuming you have &lt;a href=&#34;https://www.digitalocean.com/community/tutorials/how-to-install-r-on-ubuntu-16-04-2&#34;&gt;R installed in your Ubuntu VPS&lt;/a&gt; with your favorite packages, then make sure your script works by running &lt;code&gt;Rscript path/to/your/script.R&lt;/code&gt;. It might be better to type &lt;code&gt;which Rscript&lt;/code&gt; in the terminal and paste the path to the executable, similar to &lt;code&gt;/usr/bin/Rscript path/to/your/script.R&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;My workflow is as follows: I first create an empty dataset saved as &lt;code&gt;.rds&lt;/code&gt; and my script reads the data, scrapes the bicing data and then saves the data by appending both the empty and the scraped data. It finishes by saving the same &lt;code&gt;.rds&lt;/code&gt; for a later scrape. I tested this very thoroughly to make sure the script wouldn’t fail and I always get the expected data.&lt;/p&gt;
&lt;p&gt;All good so far, right? This took me no time. The hard problem came when setting the &lt;code&gt;cron&lt;/code&gt; job, which is a way of scheduling tasks in OSx and Ubuntu. For an explanation of how &lt;code&gt;cron&lt;/code&gt; works, check out how I set &lt;a href=&#34;blog/2017-03-08-my-pisa-twitter-bot/my-pisa-twitter-bot/index.html&#34;&gt;my PISA twitter bot&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;First, make sure you have &lt;code&gt;cron&lt;/code&gt; &lt;a href=&#34;https://www.digitalocean.com/community/tutorials/how-to-use-cron-to-automate-tasks-on-a-vps&#34;&gt;installed&lt;/a&gt;. I followed &lt;strong&gt;a lot&lt;/strong&gt; of tutorials and dispered information. What worked for me perhaps does not work for you, but here it is.&lt;/p&gt;
&lt;p&gt;Type &lt;code&gt;crontab -e&lt;/code&gt; and the cron interface should appear. The lines starting with &lt;code&gt;#&lt;/code&gt; are coments, so scroll down until the end of the comments. First we have to set a few environmental variables that &lt;code&gt;cron&lt;/code&gt; uses to execute your script. I followed &lt;a href=&#34;http://krisjordan.com/essays/timesaving-crontab-tips&#34;&gt;these tips&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;When I finished my crontab looked like this:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;SHELL=/bin/bash
PATH=/home/cimentadaj/bin:/home/cimentadaj/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
HOME=/home/cimentadaj/bicycle
MAILTO=my_email # set email here!
15,50 16  * * * /usr/bin/Rscript scrape_bicing.R&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;SHELL is the path to the pre-determined program to run on the cron job. Be default I set it to bash (but it could be anything else you want).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;PATH I’m not sure what’s for but I pasted the output of &lt;code&gt;echo $PATH&lt;/code&gt;, as the tips suggested.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;HOME is the root directory where the script will be executed, I set it to where the script is (or where your project is at).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;MAILTO is the email where I will get the cron job alert when it finishes.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;15,50 16  * * * /usr/bin/Rscript scrape_bicing.R&lt;/code&gt; is the schedule, program and script to run. Here I set arbitrary times, so the the script is scheduled to run at &lt;code&gt;16:15&lt;/code&gt; and &lt;code&gt;16:50&lt;/code&gt; every day, every month and every year. I will run using &lt;code&gt;Rscript&lt;/code&gt; and the name of the script to run.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;WARNING:&lt;/strong&gt; remember that the &lt;code&gt;cron&lt;/code&gt; is set relative to the time of where your server is. Mine did not have the same timezone of where I lived, so I had to set the &lt;code&gt;cron&lt;/code&gt; one hour before of my actual time. Use &lt;code&gt;date&lt;/code&gt; to print the time of your VPS.&lt;/p&gt;
&lt;p&gt;Even after this, the &lt;code&gt;cron&lt;/code&gt; job was still not running. Nothing, no email, no log, no change in the data. I then figured out that Ubuntu systems have some &lt;a href=&#34;https://serverfault.com/a/754104&#34;&gt;pecularities&lt;/a&gt; when it comes to &lt;code&gt;cron&lt;/code&gt;. So I went to &lt;code&gt;./etc/&lt;/code&gt; and renamed every &lt;code&gt;cron.&lt;/code&gt; file for &lt;code&gt;cron-&lt;/code&gt; with &lt;code&gt;rename &#39;s/cron./cron-/g&#39; *&lt;/code&gt;, thanks to this &lt;a href=&#34;https://stackoverflow.com/a/20657563/3617958&#34;&gt;answer&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Run again and it worked! Great. However, I didn’t receive an email stating that the &lt;code&gt;cron&lt;/code&gt; job finished. I looked up many solutions and ended up installing &lt;code&gt;ssmtp&lt;/code&gt; which is a library for sending emails from terminal. I won’t bore you with the details. Here are the steps I took:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Install &lt;code&gt;ssmtp&lt;/code&gt; with &lt;code&gt;sudo apt-get update&lt;/code&gt; and &lt;code&gt;sudo apt-get install ssmtp&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Edit &lt;code&gt;ssmtp.conf&lt;/code&gt; with &lt;code&gt;sudo nano /etc/ssmtp/ssmtp.conf&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here’s the config that worked for me using &lt;code&gt;gmail&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;# Config file for sSMTP sendmail
#
# The person who gets all mail for userids &amp;lt; 1000
# Make this empty to disable rewriting.
root=your_email@gmail.com

# The place where the mail goes. The actual machine name is required no 
# MX records are consulted. Commonly mailhosts are named mail.domain.com
mailhub=smtp.gmail.com:587

AuthUser=your_email@gmail.com
AuthPass=your_password
UseTLS=YES
UseSTARTTLS=yes
TLS_CA_FILE=/etc/ssl/certs/ca-certificates.crt

# Where will the mail seem to come from?
#rewriteDomain=gmail.com

# The full hostname
hostname=your_host_name

# Are users allowed to set their own From: address?
# YES - Allow the user to specify their own From: address
# NO - Use the system generated From: address
#FromLineOverride=YES&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Three caveats that took me a lot of time to figure out.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;First, &lt;a href=&#34;https://www.digitalocean.com/community/tutorials/how-to-use-google-s-smtp-server&#34;&gt;some docs&lt;/a&gt; say you should use another port in &lt;code&gt;mailhub&lt;/code&gt;, but &lt;code&gt;587&lt;/code&gt; worked for me.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;TLS_CA_FILE&lt;/code&gt;: make sure that &lt;a href=&#34;https://askubuntu.com/questions/342484/etc-pki-tls-certs-ca-bundle-crt-not-found&#34;&gt;this file exists&lt;/a&gt;! For Ubuntu/Debian the file is at &lt;code&gt;/etc/ssl/certs/ca-certificates.crt&lt;/code&gt; while on other platforms it might be in &lt;code&gt;/etc/pki/tls/certs/ca-bundle.crt&lt;/code&gt;. Note the different file names!&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;hostname&lt;/code&gt; should be the result of typing &lt;code&gt;hostname&lt;/code&gt; in your server.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Lastly, I also added the line &lt;code&gt;root:your_EMAIL_@gmail.com:smtp.gmail.com:587&lt;/code&gt; with &lt;code&gt;sudo nano /etc/ssmtp/revaliases&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;After an entire day figuring out all this information, the &lt;code&gt;cron&lt;/code&gt; job worked! I now set my &lt;code&gt;cron&lt;/code&gt; job and whenever it finished I receive an email directly showing the log of the script.&lt;/p&gt;
&lt;p&gt;I wrote this primarily for me not to forget any of this, but it might be useful for other people.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Scraping and visualizing How I Met Your Mother</title>
      <link>/blog/2017-10-16-scraping-and-visualizing-how-i-met-your-mother/scraping-and-visualizing-how-i-met-your-mother/</link>
      <pubDate>Mon, 16 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/blog/2017-10-16-scraping-and-visualizing-how-i-met-your-mother/scraping-and-visualizing-how-i-met-your-mother/</guid>
      <description>&lt;p&gt;How I Met Your Mother (HIMYM from here after) is a television series very similar to the classical ‘Friends’ series from the 90’s. Following the release of the &lt;a href=&#34;http://tidytextmining.com/&#34;&gt;tidy text&lt;/a&gt; book I was looking for a project in which I could apply these skills. I decided I would scrape all the transcripts from HIMYM and analyze patterns between characters. This post really took me to the limit in terms of web scraping and pattern matching, which was specifically what I wanted to improve in the first place. Let’s begin!&lt;/p&gt;
&lt;p&gt;My first task was whether there was any consistency in the URL’s that stored the transcripts. If you ever watched HIMYM, we know there’s around nine seasons, each one with about 22 episodes. This makes about 200 episodes give or take. It would be a big pain to manually write down 200 complicated URL’s. Luckily, there is a way of finding the 200 links without writing them down manually.&lt;/p&gt;
&lt;p&gt;First, we create the links for the 9 websites that contain all episodes (1 through season 9)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rvest)
library(tidyverse)
library(stringr)
library(tidytext)

main_url &amp;lt;- &amp;quot;http://transcripts.foreverdreaming.org&amp;quot;
all_pages &amp;lt;- paste0(&amp;quot;http://transcripts.foreverdreaming.org/viewforum.php?f=177&amp;amp;start=&amp;quot;, seq(0, 200, 25))
characters &amp;lt;- c(&amp;quot;ted&amp;quot;, &amp;quot;lily&amp;quot;, &amp;quot;marshall&amp;quot;, &amp;quot;barney&amp;quot;, &amp;quot;robin&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Each of the URL’s of &lt;code&gt;all_pages&lt;/code&gt; contains all episodes for that season (so around 22 URL’s). I also picked the characters we’re gonna concentrate for now. From here the job is very easy. We create a function that reads each link and parses the section containing all links for that season. We can do that using &lt;a href=&#34;http://selectorgadget.com/.&#34;&gt;SelectorGadget&lt;/a&gt; to find the section we’re interested in. We then search for the &lt;code&gt;href&lt;/code&gt; attribute to grab all links in that attribute and finally create a tibble with each episode together with it’s link.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;episode_getter &amp;lt;- function(link) {
  title_reference &amp;lt;-
    link %&amp;gt;%
    read_html() %&amp;gt;%
    html_nodes(&amp;quot;.topictitle&amp;quot;) # Get the html node name with &amp;#39;selector gadget&amp;#39;
  
  episode_links &amp;lt;-
    title_reference %&amp;gt;%
    html_attr(&amp;quot;href&amp;quot;) %&amp;gt;%
    gsub(&amp;quot;^.&amp;quot;, &amp;quot;&amp;quot;, .) %&amp;gt;%
    paste0(main_url, .) %&amp;gt;%
    setNames(title_reference %&amp;gt;% html_text()) %&amp;gt;%
    enframe(name = &amp;quot;episode_name&amp;quot;, value = &amp;quot;link&amp;quot;)
  
  episode_links
}

all_episodes &amp;lt;- map_df(all_pages, episode_getter) # loop over all seasons and get all episode links
all_episodes$id &amp;lt;- 1:nrow(all_episodes)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There we go! Now we have a very organized &lt;code&gt;tibble&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all_episodes
# # A tibble: 208 x 3
#                      episode_name
#                             &amp;lt;chr&amp;gt;
#  1                  01x01 - Pilot
#  2         01x02 - Purple Giraffe
#  3 01x03 - Sweet Taste of Liberty
#  4    01x04 - Return of the Shirt
#  5           01x05 - Okay Awesome
#  6         01x06 - Slutty Pumpkin
#  7             01x07 - Matchmaker
#  8               01x08 - The Duel
#  9   01x09 - Belly Full of Turkey
# 10 01x10 - The Pineapple Incident
# # ... with 198 more rows, and 2 more variables: link &amp;lt;chr&amp;gt;, id &amp;lt;int&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The remaining part is to actually scrape the text from each episode. We can work that out for a single episode and then turn that into a function and apply for all episodes.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;episode_fun &amp;lt;- function(file) {
  
  file %&amp;gt;%
    read_html() %&amp;gt;%
    html_nodes(&amp;quot;.postbody&amp;quot;) %&amp;gt;%
    html_text() %&amp;gt;%
    str_split(&amp;quot;\n|\t&amp;quot;) %&amp;gt;%
    .[[1]] %&amp;gt;%
    data_frame(text = .) %&amp;gt;%
    filter(str_detect(text, &amp;quot;&amp;quot;), # Lots of empty spaces
           !str_detect(text, &amp;quot;^\\t&amp;quot;), # Lots of lines with \t to delete
           !str_detect(text, &amp;quot;^\\[.*\\]$&amp;quot;), # Text that start with brackets
           !str_detect(text, &amp;quot;^\\(.*\\)$&amp;quot;), # Text that starts with parenthesis
           str_detect(text, &amp;quot;^*.:&amp;quot;), # I want only lines with start with dialogue (:)
           !str_detect(text, &amp;quot;^ad&amp;quot;)) # Remove lines that start with ad (for &amp;#39;ads&amp;#39;, the link of google ads)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above function reads each episode, turns the html text into a data frame and organizes it clearly for text analysis. For example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;episode_fun(all_episodes$link[15])
# # A tibble: 195 x 1
#                                                                           text
#                                                                          &amp;lt;chr&amp;gt;
#  1 Ted from 2030: Kids, something you might not know about your Uncle Marshall
#  2                  &amp;quot;Ted: You don&amp;#39;t have to shout out \&amp;quot;poker\&amp;quot; when you win.&amp;quot;
#  3                                     Marshall: I know. It&amp;#39;s just fun to say.
#  4 &amp;quot;Ted from 2030: We all finally agreed Marshall should be running our game n
#  5 &amp;quot;Marshall: It&amp;#39;s called \&amp;quot;Marsh-gammon.\&amp;quot; It combines all the best features 
#  6                                               Robin: Backgammon, obviously.
#  7 &amp;quot;Marshall: No. Backgammon sucks. I took the only good part of backgammon, t
#  8                                     Lily: I&amp;#39;m so excited Victoria&amp;#39;s coming.
#  9                                   Robin: I&amp;#39;m going to go get another round.
# 10 Ted: Okay, I want to lay down some ground rules for tonight. Barney, I actu
# # ... with 185 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We now have a data frame with only dialogue for each character. We need to apply that function to each episode and &lt;code&gt;bind&lt;/code&gt; everything together. We first apply the function to every episode.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all_episodes$text &amp;lt;- map(all_episodes$link, episode_fun)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;text&lt;/code&gt; list-column is an organized list with text for each episode. However, manual inspection of some episodes actually denotes a small error that limits our analysis greatly. Among the main interests of this document is to study relationships and presence between characters. For that, we need each line of text to be accompanied by the character who said it. Unfortunately, some of these scripts don’t have that.&lt;/p&gt;
&lt;p&gt;For example, check any episode from season &lt;a href=&#34;http://transcripts.foreverdreaming.org/viewforum.php?f=177&amp;amp;start=175&#34;&gt;8&lt;/a&gt; and &lt;a href=&#34;http://transcripts.foreverdreaming.org/viewforum.php?f=177&amp;amp;start=200&#34;&gt;9&lt;/a&gt;. The writer didn’t write the dialogue and just rewrote the lines. There’s nothing we can do so far to improve that and we’ll be excluding these episodes. This pattern is also present in random episodes like in season 4 or season 6. We can exclude chapters based on the number of lines we parsed. On average, each of these episodes has about 200 lines of dialogue. Anything significantly lower, like 30 or 50 lines, is an episode which doesn’t have a lot of dialogue.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all_episodes$count &amp;lt;- map_dbl(all_episodes$text, nrow)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can extend the previous &lt;code&gt;tibble&lt;/code&gt; to be a big more organized by separating the episode-season column into separate season and episo numbers.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all_episodes &amp;lt;-
  all_episodes %&amp;gt;%
  separate(episode_name, c(&amp;quot;season&amp;quot;, &amp;quot;episode&amp;quot;), &amp;quot;-&amp;quot;, extra = &amp;quot;merge&amp;quot;) %&amp;gt;%
  separate(season, c(&amp;quot;season&amp;quot;, &amp;quot;episode_number&amp;quot;), sep = &amp;quot;x&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Great! We now have a very organized &lt;code&gt;tibble&lt;/code&gt; with all the information we need. Next step is to actually break down the lines into words and start looking for general patterns. We can do that by looping through all episodes that have over 100 lines (just an arbitrary threshold) and unnesting each line for each &lt;strong&gt;valid&lt;/strong&gt; character.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lines_characters &amp;lt;-
  map(filter(all_episodes, count &amp;gt; 100) %&amp;gt;% pull(text), ~ { 
    # only loop over episodes that have over 100 lines
    .x %&amp;gt;%
      separate(text, c(&amp;quot;character&amp;quot;, &amp;quot;text&amp;quot;), sep = &amp;quot;:&amp;quot;, extra = &amp;#39;merge&amp;#39;) %&amp;gt;%
      # separate character dialogue from actual dialogo
      unnest_tokens(character, character) %&amp;gt;%
      filter(str_detect(character, paste0(paste0(&amp;quot;^&amp;quot;, characters, &amp;quot;$&amp;quot;), collapse = &amp;quot;|&amp;quot;))) %&amp;gt;%
      # only count the lines of our chosen characters
      mutate(episode_lines_id = 1:nrow(.))
  }) %&amp;gt;%
  setNames(filter(all_episodes, count &amp;gt; 100) %&amp;gt;% # name according to episode
             unite(season_episode, season, episode_number, sep = &amp;quot;x&amp;quot;) %&amp;gt;%
             pull(season_episode)) %&amp;gt;%
  enframe() %&amp;gt;%
  unnest() %&amp;gt;%
  mutate(all_lines_id = 1:nrow(.))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok, our text is sort of ready. Let’s remove some bad words.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;words_per_character &amp;lt;-
  lines_characters %&amp;gt;%
  unnest_tokens(word, text) %&amp;gt;% # expand all sentences into words
  anti_join(stop_words) %&amp;gt;% # remove bad words
  filter(!word %in% characters) %&amp;gt;% # only select characters we&amp;#39;re interested
  arrange(name) %&amp;gt;%
  separate(name, c(&amp;quot;season&amp;quot;, &amp;quot;episode&amp;quot;), sep = &amp;quot;x&amp;quot;, remove = FALSE) %&amp;gt;%
  mutate(name = factor(name, ordered = TRUE),
         season = factor(season, ordered = TRUE),
         episode = factor(episode, ordered = TRUE)) %&amp;gt;%
  filter(season != &amp;quot;07&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Just to make sure, let’s look at the &lt;code&gt;tibble&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;words_per_character
# # A tibble: 88,174 x 7
#      name season episode character episode_lines_id all_lines_id      word
#     &amp;lt;ord&amp;gt;  &amp;lt;ord&amp;gt;   &amp;lt;ord&amp;gt;     &amp;lt;chr&amp;gt;            &amp;lt;int&amp;gt;        &amp;lt;int&amp;gt;     &amp;lt;chr&amp;gt;
#  1 01x01      01     01   marshall                1            1      ring
#  2 01x01      01     01   marshall                1            1     marry
#  3 01x01      01     01        ted                2            2   perfect
#  4 01x01      01     01        ted                2            2   engaged
#  5 01x01      01     01        ted                2            2       pop
#  6 01x01      01     01        ted                2            2 champagne
#  7 01x01      01     01        ted                2            2     drink
#  8 01x01      01     01        ted                2            2     toast
#  9 01x01      01     01        ted                2            2   kitchen
# 10 01x01      01     01        ted                2            2     floor
# # ... with 88,164 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Perfect! One row per word, per character, per episode with the id of the line of the word.&lt;/p&gt;
&lt;p&gt;Alright, let’s get our hands dirty. First, let visualize the presence of each character in terms of words over time.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Filtering position of first episode of all seasons to
# position the X axis in the next plot.
first_episodes &amp;lt;-
  all_episodes %&amp;gt;%
  filter(count &amp;gt; 100, episode_number == &amp;quot;01 &amp;quot;) %&amp;gt;%
  pull(id)

words_per_character %&amp;gt;%
  split(.$name) %&amp;gt;%
  setNames(1:length(.)) %&amp;gt;%
  enframe(name = &amp;quot;episode_id&amp;quot;) %&amp;gt;%
  unnest() %&amp;gt;%
  count(episode_id, character) %&amp;gt;%
  group_by(episode_id) %&amp;gt;%
  mutate(total_n = sum(n),
         perc = round(n / total_n, 2)) %&amp;gt;%
  ggplot(aes(as.numeric(episode_id), perc, group = character, colour = character)) +
  geom_line() +
  geom_smooth(method = &amp;quot;lm&amp;quot;) +
  scale_colour_discrete(guide = FALSE) +
  scale_x_continuous(name = &amp;quot;Seasons&amp;quot;,
                     breaks = first_episodes, labels = paste0(&amp;quot;S&amp;quot;, 1:7)) +
  scale_y_continuous(name = &amp;quot;Percentage of words per episode&amp;quot;) +
  theme_minimal() +
  facet_wrap(~ character, ncol = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/2017-10-16-scraping-and-visualizing-how-i-met-your-mother/2017-10-16-scraping-and-visualizing-how-i-met-your-mother_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;768&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Ted is clearly the character with the highest number of words per episode followed by Barney. Lily and Robin, the only two women have very low presence compared to the men. In fact, if one looks closely, Lily seemed to have decreased slightly over time, having an all time low in season 4. Marshall, Lily’s partner in the show, does have much lower presence than both Barney and Ted but he has been catching up over time.&lt;/p&gt;
&lt;p&gt;We also see an interesting pattern where Barney has a lot of peaks, suggesting that in some specific episodes he gains predominance, where Ted has an overall higher level of words per episode. And when Ted has peaks, it’s usually below its trend-line.&lt;/p&gt;
&lt;p&gt;Looking at the distribution:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# devtools::install_github(&amp;quot;clauswilke/ggjoy&amp;quot;)
library(ggjoy)

words_per_character %&amp;gt;%
  split(.$name) %&amp;gt;%
  setNames(1:length(.)) %&amp;gt;%
  enframe(name = &amp;quot;episode_id&amp;quot;) %&amp;gt;%
  unnest() %&amp;gt;%
  count(season, episode_id, character) %&amp;gt;%
  group_by(episode_id) %&amp;gt;%
  mutate(total_n = sum(n),
         perc = round(n / total_n, 2)) %&amp;gt;%
  ggplot(aes(x = perc, y = character, fill = character)) +
  geom_joy(scale = 0.85) +
  scale_fill_discrete(guide = F) +
  scale_y_discrete(name = NULL, expand=c(0.01, 0)) +
  scale_x_continuous(name = &amp;quot;Percentage of words&amp;quot;, expand=c(0.01, 0)) +
  ggtitle(&amp;quot;Percentage of words per season&amp;quot;) +
  facet_wrap(~ season, ncol = 7) +
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/2017-10-16-scraping-and-visualizing-how-i-met-your-mother/2017-10-16-scraping-and-visualizing-how-i-met-your-mother_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;we see the differences much clearer. For example, we see Barney’s peaks through out every season with Season 6 seeing a clear peak of 40%. On the other hand, we see that their distributions don’t change that much over time! Suggesting that the presence of each character is very similar in all seasons. Don’t get me wrong, there are differences like Lily in Season 2 and then in Season 6, but in overall terms the previous plot suggests no increase over seasons, and this plot suggests that between seasons, there’s not a lot of change in their distributions that affects the overall mean.&lt;/p&gt;
&lt;p&gt;If you’ve watched the TV series, you’ll remember Barney always repeating one similar trademark word: legendary! Although it is a bit cumbersome for us to count the number of occurrences of that sentence once we unnested each sentence, we can at least count the number of words per character and see whether some characters have particular words.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;count_words &amp;lt;-
  words_per_character %&amp;gt;%
  filter(!word %in% characters) %&amp;gt;%
  count(character, word, sort = TRUE)

count_words %&amp;gt;%
  group_by(character) %&amp;gt;%
  top_n(20) %&amp;gt;%
  ggplot(aes(reorder(word, n), n)) +
  geom_col(alpha = 0.8) +
  coord_flip() +
  facet_wrap(~ character, scales = &amp;quot;free_y&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/2017-10-16-scraping-and-visualizing-how-i-met-your-mother/2017-10-16-scraping-and-visualizing-how-i-met-your-mother_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Here we see that a lot of the words we capture are actually nouns or expressions which are common to everyone, such as ‘yeah’, ‘hey’ or ‘time’. We can weight down commonly used words for other words which are important but don’t get repeated a lot. We can exclude those words using &lt;code&gt;bind_tf_idf()&lt;/code&gt;, which for each character decreases the weight for commonly used words and increases the weight for words that are not used very much in a collection or corpus of documents (see 3.3 in &lt;a href=&#34;http://tidytextmining.com/tfidf.html&#34; class=&#34;uri&#34;&gt;http://tidytextmining.com/tfidf.html&lt;/a&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;count_words %&amp;gt;%
  bind_tf_idf(word, character, n) %&amp;gt;%
  arrange(desc(tf_idf)) %&amp;gt;%
  group_by(character) %&amp;gt;%
  top_n(20) %&amp;gt;%
  ggplot(aes(reorder(word, n), n)) +
  geom_col(alpha = 0.8) +
  coord_flip() +
  facet_wrap(~ character, scales = &amp;quot;free_y&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/2017-10-16-scraping-and-visualizing-how-i-met-your-mother/2017-10-16-scraping-and-visualizing-how-i-met-your-mother_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now Barney has a very distinctive word usage, one particularly sexist with words such as couger, bang and tits. Also, we see the word legendary as the thirdly repeated word, something we were expecting! On the other hand, we see Ted with things like professor (him), aunt (because of aunt Lily and such).&lt;/p&gt;
&lt;p&gt;Knowing that Ted is the main character in the series is no surprise. To finish off, we’re interested in knowing which characters are related to each other. First, let’s turn the data frame into a suitable format.&lt;/p&gt;
&lt;p&gt;Here we turn all lines to lower case and check which characters are present in the text of each dialogue. The loop will return a vector of logicals whether there was a mention of any of the characters. For simplicity I exclude all lines where there is more than 1 mention of a character, that is, 2 or more characters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lines_characters &amp;lt;-
  lines_characters %&amp;gt;%
  mutate(text = str_to_lower(text))

rows_fil &amp;lt;-
  map(characters, ~ str_detect(lines_characters$text, .x)) %&amp;gt;%
  reduce(`+`) %&amp;gt;%
  ifelse(. &amp;gt;= 2, 0, .) # excluding sentences which have 2 or more mentions for now
  # ideally we would want to choose to count the number of mentions
  # per line or randomly choose another a person that was mentioned.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that we have the rows that have a mention of another character, we subset only those rows. Then we want know which character was mentioned in which line. I loop through each line and test which character is present in that specific dialogue line. The loop returns the actual character name for each dialogue. Because we already filtered lines that &lt;strong&gt;have&lt;/strong&gt; a character name mentioned, the loop should return a vector of the same length.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;character_relation &amp;lt;-
  lines_characters %&amp;gt;%
  filter(as.logical(rows_fil)) %&amp;gt;%
  mutate(who_said_what =
           map_chr(.$text, ~ { # loop over all each line
             who_said_what &amp;lt;- map_lgl(characters, function(.y) str_detect(.x, .y))
             # loop over each character and check whether he/she was mentioned
             # in that line
             characters[who_said_what]
             # subset the character that matched
           }))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we plot the relationship using the &lt;code&gt;ggraph&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggraph)
library(igraph)

character_relation %&amp;gt;%
  count(character, who_said_what) %&amp;gt;%
  graph_from_data_frame() %&amp;gt;%
  ggraph(layout = &amp;quot;linear&amp;quot;, circular = TRUE) +
  geom_edge_arc(aes(edge_alpha = n, edge_width = n),
                width = 2.5, show.legend = FALSE) +
  geom_node_text(aes(label = name), repel = TRUE) +
  theme_void()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/2017-10-16-scraping-and-visualizing-how-i-met-your-mother/2017-10-16-scraping-and-visualizing-how-i-met-your-mother_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A very clear pattern emerges. There is a strong relationship between Robin and Barney towards Ted. In fact, their direct relationship is very weak, but both are very well connected to Ted. On the other hand, Marshall and Lily are also reasonably connected to Ted but with a weaker link. Both of them are indeed very connected, as should be expected since they were a couple in the TV series.&lt;/p&gt;
&lt;p&gt;We also see that the weakest members of the group are Robin and Barney with only strong bonds toward Ted but no strong relationship with the other from the group. Overall, there seems to be a division: Marshall and Lily hold a somewhat close relationship with each other and towards Ted and Barney and Robin tend to be related to Ted but no one else.&lt;/p&gt;
&lt;p&gt;As a follow-up question, is this pattern of relationships the same across all seasons? We can do that very quickly by filtering each season using the previous plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(cowplot)

# Loop through each season
seasons &amp;lt;- paste0(0, 1:7)

all_season_plots &amp;lt;- lapply(seasons, function(season_num) {

  set.seed(2131)
  
  character_relation %&amp;gt;%
    # Extract the season number from the `name` column
    mutate(season = str_replace_all(character_relation$name, &amp;quot;x(.*)$&amp;quot;, &amp;quot;&amp;quot;)) %&amp;gt;%
    filter(season == season_num) %&amp;gt;%
    count(character, who_said_what) %&amp;gt;%
    graph_from_data_frame() %&amp;gt;%
    ggraph(layout = &amp;quot;linear&amp;quot;, circular = TRUE) +
    geom_edge_arc(aes(edge_alpha = n, edge_width = n),
                  width = 2.5, show.legend = FALSE) +
    geom_node_text(aes(label = name), repel = TRUE) +
    theme_void()
})

# Plot all graphs side-by-side
cowplot::plot_grid(plotlist = all_season_plots, labels = seasons)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/2017-10-16-scraping-and-visualizing-how-i-met-your-mother/2017-10-16-scraping-and-visualizing-how-i-met-your-mother_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;960&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There are reasonable changes for all non-Ted relationship! For example, for season 2 the relationship Marshall-Lily-Ted becomes much stronger and it disappears in season 3. Let’s remember that these results might be affected by the fact that I excluded some episodes because of low number of dialogue lines. Keeping that in mind, we also see that for season 7 the Robin-Barney relationship became much stronger (is this the season the started dating?). All in all, the relationships don’t look dramatically different from the previous plot. Everyone seems to be strongly related to Ted. The main difference is the changes in relationship between the other members of the cast.&lt;/p&gt;
&lt;p&gt;This dataset has a lot of potential and I’m sure I’ve scratched the surface of what one can do with this data. I encourage anyone interested in the topic to use the code to analyze the data further. One idea I might explore in the future is to build a model that attempts to predict who said what for all dialogue lines that didn’t have a character member. This can be done by extracting features from all sentences and using these patterns try to classify which. Any feedback is welcome, so feel free to message me at &lt;a href=&#34;mailto:cimentadaj@gmail.com&#34;&gt;cimentadaj@gmail.com&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
